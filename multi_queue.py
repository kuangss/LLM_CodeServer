import threading
import queue
from typing import Generator, Callable, Any, List, Tuple
import time
from concurrent.futures import ThreadPoolExecutor

class ParallelGenerators:
    """
    å¹¶è¡Œæ‰§è¡Œå¤šä¸ªç”Ÿæˆå™¨çš„ç±»
    """
    
    def __init__(self, max_workers: int = None):
        self.max_workers = max_workers
        self._result_queue = queue.Queue()
        self._done_queue = queue.Queue()
        self._workers: List[threading.Thread] = []
        self._thread_pool = ThreadPoolExecutor(max_workers=max_workers)
    
    def add_generator(self, 
                     generator_func: Callable, 
                     *args, 
                     **kwargs) -> None:
        """æ·»åŠ ä¸€ä¸ªç”Ÿæˆå™¨ä»»åŠ¡"""
        worker_id = len(self._workers)
        future = self._thread_pool.submit(
            self._run_generator,
            generator_func, args, kwargs, worker_id
        )
        # åˆ›å»ºä¸€ä¸ªè½»é‡çº§çš„çº¿ç¨‹å…¼å®¹å¯¹è±¡
        class WorkerWrapper:
            def __init__(self, future):
                self.future = future
            
            def is_alive(self):
                return not self.future.done()
            
            def join(self, timeout=None):
                if not self.future.done():
                    try:
                        self.future.result(timeout=timeout)
                    except Exception:
                        pass  # å¼‚å¸¸å·²åœ¨ _run_generator ä¸­å¤„ç†
        
        self._workers.append(WorkerWrapper(future))
    
    def _run_generator(self, 
                      generator_func: Callable, 
                      args: Tuple, 
                      kwargs: dict, 
                      worker_id: int):
        """åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œç”Ÿæˆå™¨"""
        try:
            for item in generator_func(*args, **kwargs):
                self._result_queue.put(item)
        except Exception as e:
            self._result_queue.put(("ERROR", str(e)))
        finally:
            self._done_queue.put(worker_id)
    
    def start(self) -> Generator[Any, None, None]:
        """å¯åŠ¨æ‰€æœ‰ç”Ÿæˆå™¨å¹¶è¿”å›ç»Ÿä¸€çš„ç»“æœç”Ÿæˆå™¨"""
        # è¿”å›ç”Ÿæˆå™¨
        completed = set()
        
        while True:
            # é¦–å…ˆå°è¯•è·å–æ‰€æœ‰å¯ç”¨çš„ç»“æœ
            items_yielded = False
            while True:
                try:
                    item = self._result_queue.get_nowait()
                    # æ›´ç²¾ç¡®çš„é”™è¯¯æ£€æµ‹
                    if isinstance(item, tuple) and len(item) == 2 and item[0] == "ERROR":
                        raise RuntimeError(f"ç”Ÿæˆå™¨é”™è¯¯: {item[1]}")
                    yield item
                    items_yielded = True
                except queue.Empty:
                    break
            
            # æ£€æŸ¥å®Œæˆä¿¡å·
            while True:
                try:
                    done_id = self._done_queue.get_nowait()
                    completed.add(done_id)
                except queue.Empty:
                    break
            
            # å¦‚æœæ‰€æœ‰çº¿ç¨‹éƒ½å®Œæˆäº†ï¼Œå¤„ç†å‰©ä½™ç»“æœå¹¶é€€å‡º
            if len(completed) >= len(self._workers):
                # è·å–æ‰€æœ‰å‰©ä½™ç»“æœ
                while not self._result_queue.empty():
                    item = self._result_queue.get_nowait()
                    if isinstance(item, tuple) and item[0] == "ERROR":
                        raise RuntimeError(f"ç”Ÿæˆå™¨é”™è¯¯: {item[1]}")
                    yield item
                break
            
            # å¦‚æœæ²¡æœ‰äº§å‡ºä»»ä½•é¡¹ç›®ä¸”çº¿ç¨‹ä»åœ¨è¿è¡Œï¼ŒçŸ­æš‚ç­‰å¾…
            if not items_yielded:
                if all(not t.is_alive() for t in self._workers):
                    # æ‰€æœ‰çº¿ç¨‹éƒ½å·²ç»“æŸï¼Œè·å–å‰©ä½™ç»“æœ
                    while not self._result_queue.empty():
                        item = self._result_queue.get_nowait()
                        if isinstance(item, tuple) and item[0] == "ERROR":
                            raise RuntimeError(f"ç”Ÿæˆå™¨é”™è¯¯: {item[1]}")
                        yield item
                    break
                # çŸ­æš‚ç­‰å¾…é¿å…CPUå ç”¨è¿‡é«˜
                time.sleep(0.01)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for thread in self._workers:
            thread.join(timeout=1)
    
    def shutdown(self, wait: bool = True):
        """å…³é—­çº¿ç¨‹æ± """
        self._thread_pool.shutdown(wait=wait)
    
    def __enter__(self):
        """æ”¯æŒä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        return self
    
    def __exit__(self, _exc_type, _exc_val, _exc_tb):
        """é€€å‡ºä¸Šä¸‹æ–‡æ—¶è‡ªåŠ¨å…³é—­çº¿ç¨‹æ± """
        self.shutdown()
        return False  # ä¸æŠ‘åˆ¶å¼‚å¸¸
    
    def __call__(self, *generator_configs) -> Generator[Any, None, None]:
        """å¿«æ·è°ƒç”¨æ–¹å¼"""
        for config in generator_configs:
            if isinstance(config, tuple) and len(config) >= 2:
                self.add_generator(config[0], *config[1])
            else:
                self.add_generator(config)
        
        return self.start()

# ä½¿ç”¨ç¤ºä¾‹
def example_generator(name: str, count: int):
    for i in range(count):
        time.sleep(0.1)  # å‡å°‘å»¶è¿Ÿç”¨äºæµ‹è¯•
        yield f"{name}: {i}"

# ä¾èµ–é“¾ä»»åŠ¡ç¤ºä¾‹
def stage1_processor(data: List[int]) -> Generator[str, None, None]:
    """ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®å¤„ç†"""
    for i, item in enumerate(data):
        time.sleep(0.05)
        yield f"Stage1-Processed-{i}: {item * 2}"

def stage2_processor(stage1_results: List[str]) -> Generator[str, None, None]:
    """ç¬¬äºŒé˜¶æ®µï¼šåŸºäºç¬¬ä¸€é˜¶æ®µç»“æœçš„å¤„ç†"""
    for i, result in enumerate(stage1_results):
        time.sleep(0.05)
        # æå–æ•°å­—å¹¶ç»§ç»­å¤„ç†
        number = int(result.split(': ')[1])
        yield f"Stage2-Enhanced-{i}: {number + 100}"

def stage3_processor(stage2_results: List[str]) -> Generator[str, None, None]:
    """ç¬¬ä¸‰é˜¶æ®µï¼šæœ€ç»ˆå¤„ç†"""
    for i, result in enumerate(stage2_results):
        time.sleep(0.05)
        number = int(result.split(': ')[1])
        yield f"Final-Result-{i}: {number ** 0.5:.2f}"

def dependent_pipeline_example():
    """ä¾èµ–ç®¡é“ç¤ºä¾‹ï¼šæ¯ä¸ªé˜¶æ®µä¾èµ–å‰ä¸€é˜¶æ®µçš„ç»“æœ"""
    print("=== ä¾èµ–ç®¡é“ç¤ºä¾‹ ===")
    
    # åˆå§‹æ•°æ®
    initial_data = [1, 2, 3, 4, 5]
    
    # ç¬¬ä¸€é˜¶æ®µ
    print("é˜¶æ®µ1ï¼šå¤„ç†åˆå§‹æ•°æ®...")
    with ParallelGenerators(max_workers=3) as stage1:
        # å°†æ•°æ®åˆ†æ‰¹å¹¶è¡Œå¤„ç†
        batch_size = 2
        for i in range(0, len(initial_data), batch_size):
            batch = initial_data[i:i+batch_size]
            stage1.add_generator(stage1_processor, batch)
        
        stage1_results = list(stage1.start())
        print(f"é˜¶æ®µ1å®Œæˆï¼Œå¾—åˆ° {len(stage1_results)} ä¸ªç»“æœ:")
        for result in stage1_results:
            print(f"  {result}")
    
    # ç¬¬äºŒé˜¶æ®µï¼šä¾èµ–ç¬¬ä¸€é˜¶æ®µç»“æœ
    print("\né˜¶æ®µ2ï¼šåŸºäºé˜¶æ®µ1ç»“æœè¿›è¡Œå¤„ç†...")
    with ParallelGenerators(max_workers=2) as stage2:
        batch_size = 3
        for i in range(0, len(stage1_results), batch_size):
            batch = stage1_results[i:i+batch_size]
            stage2.add_generator(stage2_processor, batch)
        
        stage2_results = list(stage2.start())
        print(f"é˜¶æ®µ2å®Œæˆï¼Œå¾—åˆ° {len(stage2_results)} ä¸ªç»“æœ:")
        for result in stage2_results:
            print(f"  {result}")
    
    # ç¬¬ä¸‰é˜¶æ®µï¼šä¾èµ–ç¬¬äºŒé˜¶æ®µç»“æœ
    print("\né˜¶æ®µ3ï¼šæœ€ç»ˆå¤„ç†...")
    with ParallelGenerators(max_workers=2) as stage3:
        batch_size = 2
        for i in range(0, len(stage2_results), batch_size):
            batch = stage2_results[i:i+batch_size]
            stage3.add_generator(stage3_processor, batch)
        
        final_results = list(stage3.start())
        print(f"é˜¶æ®µ3å®Œæˆï¼Œå¾—åˆ° {len(final_results)} ä¸ªæœ€ç»ˆç»“æœ:")
        for result in final_results:
            print(f"  {result}")
    
    print("\n=== ç®¡é“å¤„ç†å®Œæˆ ===")

def adaptive_dependent_example():
    """è‡ªé€‚åº”ä¾èµ–ç¤ºä¾‹ï¼šæ ¹æ®å‰ä¸€é˜¶æ®µç»“æœåŠ¨æ€è°ƒæ•´ä¸‹ä¸€é˜¶æ®µ"""
    print("\n=== è‡ªé€‚åº”ä¾èµ–ç¤ºä¾‹ ===")
    
    # é˜¶æ®µ1ï¼šæ•°æ®æ”¶é›†
    def data_collector(source_id: int) -> Generator[str, None, None]:
        for i in range(3):
            time.sleep(0.02)
            yield f"Data-Source{source_id}-Item{i}: {source_id * 10 + i}"
    
    with ParallelGenerators(max_workers=3) as collector:
        for source_id in range(1, 4):
            collector.add_generator(data_collector, source_id)
        
        collected_data = list(collector.start())
        print(f"æ”¶é›†åˆ° {len(collected_data)} æ¡æ•°æ®:")
        for data in collected_data:
            print(f"  {data}")
    
    # é˜¶æ®µ2ï¼šæ ¹æ®æ•°æ®é‡åŠ¨æ€åˆ†é…å¤„ç†å™¨
    def data_processor(data_batch: List[str]) -> Generator[str, None, None]:
        for i, data in enumerate(data_batch):
            time.sleep(0.03)
            # æå–æ•°å€¼è¿›è¡Œå¤„ç†
            value = int(data.split(': ')[1])
            processed_value = value * value
            yield f"Processed-{i}: {processed_value}"
    
    # æ ¹æ®æ•°æ®é‡åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°
    batch_size = max(1, len(collected_data) // 2)
    print(f"\næ ¹æ®æ•°æ®é‡ {len(collected_data)}ï¼Œè®¾ç½®æ‰¹æ¬¡å¤§å°ä¸º {batch_size}")
    
    with ParallelGenerators(max_workers=2) as processor:
        for i in range(0, len(collected_data), batch_size):
            batch = collected_data[i:i+batch_size]
            processor.add_generator(data_processor, batch)
        
        processed_data = list(processor.start())
        print(f"å¤„ç†å®Œæˆï¼Œå¾—åˆ° {len(processed_data)} ä¸ªç»“æœ:")
        for result in processed_data:
            print(f"  {result}")
    
    # é˜¶æ®µ3ï¼šç»“æœèšåˆ
    def result_aggregator(results: List[str]) -> Generator[str, None, None]:
        total = sum(int(r.split(': ')[1]) for r in results)
        time.sleep(0.01)
        yield f"Aggregated-Total: {total}"
        yield f"Aggregated-Average: {total / len(results):.2f}"
        yield f"Aggregated-Count: {len(results)}"
    
    with ParallelGenerators(max_workers=1) as aggregator:
        aggregator.add_generator(result_aggregator, processed_data)
        
        final_stats = list(aggregator.start())
        print(f"\næœ€ç»ˆç»Ÿè®¡ç»“æœ:")
        for stat in final_stats:
            print(f"  {stat}")
    
    print("=== è‡ªé€‚åº”å¤„ç†å®Œæˆ ===")

def real_time_pipeline_example():
    """å®æ—¶æµæ°´çº¿ç¤ºä¾‹ï¼šç¬¬ä¸€å¾ªç¯äº§ç”Ÿç»“æœåç«‹å³å¯åŠ¨ç¬¬äºŒå¾ªç¯"""
    print("=== å®æ—¶æµæ°´çº¿ç¤ºä¾‹ ===")
    
    # ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®ç”Ÿäº§è€…
    def data_producer() -> Generator[str, None, None]:
        """ç”Ÿäº§æ•°æ®æ‰¹æ¬¡"""
        for batch_id in range(1, 4):
            for i in range(3):
                time.sleep(0.05)
                yield f"Batch{batch_id}-Item{i}: {batch_id * 100 + i}"
    
    # ç¬¬äºŒé˜¶æ®µï¼šå®æ—¶å¤„ç†å™¨
    def real_time_processor(item: str) -> Generator[str, None, None]:
        """å¤„ç†å•ä¸ªæ•°æ®é¡¹"""
        time.sleep(0.03)
        value = int(item.split(': ')[1])
        processed = value * 2
        yield f"Processed-{item}: {processed}"
    
    # ç¬¬ä¸‰é˜¶æ®µï¼šæœ€ç»ˆèšåˆå™¨
    def final_aggregator(processed_item: str) -> Generator[str, None, None]:
        """æœ€ç»ˆèšåˆå¤„ç†"""
        time.sleep(0.02)
        original = processed_item.split('Processed-')[1]
        value = int(original.split(': ')[1])
        yield f"Final-{value}: {value ** 0.5:.2f}"
    
    print("å¯åŠ¨å®æ—¶æµæ°´çº¿å¤„ç†...")
    
    # ä½¿ç”¨åµŒå¥—çš„ParallelGeneratorså®ç°æµæ°´çº¿
    final_results = []
    
    with ParallelGenerators(max_workers=2) as producers:
        # å¯åŠ¨ç”Ÿäº§è€…
        producers.add_generator(data_producer)
        
        # å¯¹æ¯ä¸ªç”Ÿäº§ç»“æœç«‹å³å¯åŠ¨å¤„ç†
        with ParallelGenerators(max_workers=3) as processors:
            with ParallelGenerators(max_workers=2) as aggregators:
                
                for produced_item in producers.start():
                    print(f"ğŸ“¦ ç”Ÿäº§: {produced_item}")
                    
                    # ç«‹å³ä¸ºæ­¤é¡¹å¯åŠ¨å¤„ç†å™¨
                    processors.add_generator(real_time_processor, produced_item)
                    
                    # æ”¶é›†å¤„ç†ç»“æœ
                    processed_items = list(processors.start())
                    for processed_item in processed_items:
                        print(f"âš™ï¸  å¤„ç†: {processed_item}")
                        
                        # ç«‹å³ä¸ºæ­¤é¡¹å¯åŠ¨èšåˆå™¨
                        aggregators.add_generator(final_aggregator, processed_item)
                        
                        # æ”¶é›†æœ€ç»ˆç»“æœ
                        final_items = list(aggregators.start())
                        for final_item in final_items:
                            final_results.append(final_item)
                            print(f"âœ… èšåˆ: {final_item}")
    
    print(f"\næµæ°´çº¿å®Œæˆï¼æœ€ç»ˆå¤„ç†äº† {len(final_results)} ä¸ªé¡¹ç›®")

def streaming_dependent_example():
    """æµå¼ä¾èµ–ç¤ºä¾‹ï¼šåŸºäºå‰ä¸€ä¸ªç»“æœåŠ¨æ€å†³å®šä¸‹ä¸€æ­¥"""
    print("\n=== æµå¼ä¾èµ–ç¤ºä¾‹ ===")
    
    # åŠ¨æ€å†³ç­–å¤„ç†å™¨
    def dynamic_processor(data: str) -> Generator[str, None, None]:
        """æ ¹æ®è¾“å…¥åŠ¨æ€å†³å®šå¤„ç†ç­–ç•¥"""
        value = int(data.split(': ')[1])
        
        if value < 150:
            # å°å€¼ï¼šç®€å•å¤„ç†
            time.sleep(0.02)
            yield f"Simple-{data}: {value + 10}"
        elif value < 200:
            # ä¸­å€¼ï¼šå¤æ‚å¤„ç†
            time.sleep(0.04)
            yield f"Complex-{data}: {value * 1.5}"
        else:
            # å¤§å€¼ï¼šå¤šé‡å¤„ç†
            time.sleep(0.06)
            yield f"Multi-{data}: {value ** 2}"
    
    # åç»­å¤„ç†å™¨
    def follow_up_processor(processed_data: str) -> Generator[str, None, None]:
        """æ ¹æ®å‰ä¸€æ­¥ç»“æœè¿›è¡Œåç»­å¤„ç†"""
        if "Simple" in processed_data:
            time.sleep(0.01)
            value = int(processed_data.split(': ')[1])
            yield f"FollowUp-Simple: {value * 3}"
        elif "Complex" in processed_data:
            time.sleep(0.02)
            value = int(processed_data.split(': ')[1])
            yield f"FollowUp-Complex: {value / 2}"
        else:  # Multi
            time.sleep(0.03)
            value = int(processed_data.split(': ')[1])
            yield f"FollowUp-Multi: {value ** 0.5}"
    
    print("å¯åŠ¨æµå¼ä¾èµ–å¤„ç†...")
    
    with ParallelGenerators(max_workers=3) as stage1:
        with ParallelGenerators(max_workers=2) as stage2:
            
            # ç¬¬ä¸€é˜¶æ®µï¼šåˆå§‹æ•°æ®ç”Ÿæˆ
            def initial_data_generator():
                for i in range(5):
                    time.sleep(0.03)
                    yield f"Data-{i}: {100 + i * 25}"
            
            stage1.add_generator(initial_data_generator)
            
            # æµå¼å¤„ç†
            for data in stage1.start():
                print(f"ğŸ“Š è¾“å…¥: {data}")
                
                # ç«‹å³å¯åŠ¨åŠ¨æ€å¤„ç†å™¨
                stage2.add_generator(dynamic_processor, data)
                
                # è·å–åŠ¨æ€å¤„ç†ç»“æœ
                for processed in stage2.start():
                    print(f"ğŸ”„ åŠ¨æ€å¤„ç†: {processed}")
                    
                    # ç«‹å³å¯åŠ¨åç»­å¤„ç†
                    stage2.add_generator(follow_up_processor, processed)
                    
                    for final in stage2.start():
                        print(f"ğŸ¯ æœ€ç»ˆç»“æœ: {final}")

def main3():
    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è‡ªåŠ¨ç®¡ç†çº¿ç¨‹æ± 
    with ParallelGenerators(max_workers=4) as parallel:
        # æ·»åŠ å¤šä¸ªç”Ÿæˆå™¨
        parallel.add_generator(example_generator, "Worker1", 3)
        parallel.add_generator(example_generator, "Worker2", 5)
        parallel.add_generator(example_generator, "Worker3", 2)
        
        # è·å–ç»Ÿä¸€ç”Ÿæˆå™¨å¹¶æ¶ˆè´¹
        for result in parallel.start():
            print(result)
    
    print("\n--- ä½¿ç”¨å¿«æ·æ–¹å¼ ---\n")
    
    # å¿«æ·æ–¹å¼ï¼ˆæ‰‹åŠ¨ç®¡ç†çº¿ç¨‹æ± ï¼‰
    parallel2 = ParallelGenerators(max_workers=2)
    try:
        gen = parallel2(
            (example_generator, ["A", 2]),
            (example_generator, ["B", 4]),
            (example_generator, ["C", 3])
        )
        
        for result in gen:
            print(result)
    finally:
        # æ‰‹åŠ¨å…³é—­çº¿ç¨‹æ± 
        parallel2.shutdown()

def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("=== åŸºç¡€å¹¶è¡Œç¤ºä¾‹ ===")
    main3()
    
    # è¿è¡Œä¾èµ–ç®¡é“ç¤ºä¾‹
    dependent_pipeline_example()
    
    # è¿è¡Œè‡ªé€‚åº”ä¾èµ–ç¤ºä¾‹
    adaptive_dependent_example()
    
    # è¿è¡Œå®æ—¶æµæ°´çº¿ç¤ºä¾‹
    real_time_pipeline_example()
    
    # è¿è¡Œæµå¼ä¾èµ–ç¤ºä¾‹
    streaming_dependent_example()

def demo_realtime_only():
    """ä»…æ¼”ç¤ºå®æ—¶æµæ°´çº¿ç¤ºä¾‹"""
    real_time_pipeline_example()

if __name__ == "__main__":
    # main()  # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    demo_realtime_only()  # ä»…è¿è¡Œå®æ—¶æµæ°´çº¿ç¤ºä¾‹